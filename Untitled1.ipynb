{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#!pip install catboost\n",
    "#import catboost as cat\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(data):\n",
    "    \n",
    "    '''\n",
    "    Function to input missing values based on the column object type\n",
    "    '''\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    for col in cols:\n",
    "        if data[col].dtype == 'int64' or data[col].dtype == 'float64':\n",
    "        \n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "        \n",
    "        #elif data[col].dtype == 'O' or data[col].dtype == 'object':\n",
    "        #    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            \n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            \n",
    "    return data\n",
    " \n",
    "def one_hot_encoding(traindata, *args):\n",
    "    \n",
    "    for ii in args:\n",
    "        traindata = pd.get_dummies(traindata, prefix=[ii], columns=[ii])\n",
    "        \n",
    "    return traindata\n",
    " \n",
    "def drop_columns(traindata, *args):\n",
    "    \n",
    "    #labels = np.array(traindata[target])\n",
    "    \n",
    "    columns = []\n",
    "    for _ in args:\n",
    "        columns.append(_)\n",
    "        \n",
    "    traindata = traindata.drop(columns, axis=1)\n",
    "    #traindata = traindata.drop(target, axis=1)\n",
    "    #testdata = testdata.drop(columns, axis=1)\n",
    "        \n",
    "    return traindata\n",
    " \n",
    "def process(traindata):\n",
    "    \n",
    "    cols = list(traindata.columns)\n",
    "    for _ in cols:\n",
    "        traindata[_] = np.where(traindata[_] == np.inf, -999, traindata[_])\n",
    "        traindata[_] = np.where(traindata[_] == np.nan, -999, traindata[_])\n",
    "        traindata[_] = np.where(traindata[_] == -np.inf, -999, traindata[_])\n",
    "        \n",
    "    return traindata\n",
    " \n",
    "def show_evaluation(pred, true):\n",
    "  print(f'Default score: {score(true.values, pred)}')\n",
    "  print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
    "  print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
    " \n",
    "def freq_encode(data, cols):\n",
    "    for i in cols:\n",
    "        encoding = data.groupby(i).size()\n",
    "        encoding = encoding/len(data)\n",
    "        data[i + '_enc'] = data[i].map(encoding)\n",
    "    return data\n",
    " \n",
    " \n",
    "def mean_target(data, cols):\n",
    "    kf = KFold(5)\n",
    "    a = pd.DataFrame()\n",
    "    for tr_ind, val_ind in kf.split(data):\n",
    "        X_tr, X_val= data.iloc[tr_ind].copy(), data.iloc[val_ind].copy()\n",
    "        for col in cols:\n",
    "            means = X_val[col].map(X_tr.groupby(col).default_status.mean())\n",
    "            X_val[col + '_mean_target'] = means + 0.0001\n",
    "        a = pd.concat((a, X_val))\n",
    "    #prior = FORCE_2020_LITHOFACIES_LITHOLOGY.mean()\n",
    "    #a.fillna(prior, inplace=True)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "sample = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.default_status\n",
    "target_numbers = {'yes': 1,\n",
    "                  'no': 0}\n",
    "\n",
    "target = target.map(target_numbers)\n",
    "train.default_status = target.map(target_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 52)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "#target = train.default_status.copy()\n",
    "df = pd.concat((train, test)).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 53)\n"
     ]
    }
   ],
   "source": [
    "df = freq_encode(df, ['form_field47'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 54)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mean_target(df, ['form_field47'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 55)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['form_field47']\n",
    " \n",
    "df = one_hot_encoding(df, *col)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2.default_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 53) (24000, 53)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Applicant_ID'], axis=1)\n",
    "df.shape\n",
    " \n",
    "df = df.fillna(-999)\n",
    "df = process(df)\n",
    "data = df.copy()\n",
    " \n",
    "train2 = data[:ntrain].copy()\n",
    "#target = train2.default_status.copy()\n",
    "#validation1_target = valid1.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
    "#validation2_target = valid2.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
    "train2.drop(['default_status'], axis=1, inplace=True)\n",
    " \n",
    "test2 = data[ntrain:(ntest+ntrain)].copy()\n",
    "test2.drop(['default_status'], axis=1, inplace=True)\n",
    "test2 = test2.reset_index(drop=True)\n",
    " \n",
    "#validation1 = data[(ntest+ntrain):(ntest+ntrain+nvalid1)].copy()\n",
    "#validation1.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
    "#validation1 = validation1.reset_index(drop=True)\n",
    " \n",
    "#validation2 = data[(ntrain+ntest+nvalid1): (ntrain+ntest+nvalid1+nvalid2)].copy()\n",
    "#validation2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
    "#validation2 = validation2.reset_index(drop=True)\n",
    " \n",
    " \n",
    "#validation3 = data[(ntrain+ntest+nvalid1+nvalid2):].copy()\n",
    "#validation3.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
    "#validation3 = validation3.reset_index(drop=True)\n",
    " \n",
    "print(train2.shape, test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = train2\n",
    "testdata = test2\n",
    " \n",
    "scaler = preprocessing.StandardScaler().fit(traindata)\n",
    "def scale_data(data):\n",
    "  \n",
    "  data = scaler.transform(data)\n",
    "  #testdata = scaler.transform(testdata)\n",
    "  data = pd.DataFrame(data, columns=testdata.columns)\n",
    " \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = scale_data(traindata)\n",
    "testdata = scale_data(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22400, 53) (22400,) (33600, 53) (33600,)\n"
     ]
    }
   ],
   "source": [
    "validation, traindata, valid_target, target = ms.train_test_split(traindata, target, random_state=405, test_size=0.6, stratify=target)\n",
    "print(validation.shape, valid_target.shape, traindata.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30240, 53), (3360, 53))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata, x_test, target, y_test = ms.train_test_split(traindata, target, random_state=405, test_size=0.1, stratify=target)\n",
    "traindata.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40623    0\n",
       "5714     0\n",
       "37749    0\n",
       "7581     0\n",
       "7616     0\n",
       "        ..\n",
       "6691     0\n",
       "50345    1\n",
       "50616    0\n",
       "19352    0\n",
       "48557    0\n",
       "Name: default_status, Length: 30240, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:17] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.78893\n",
      "Will train until validation_0-auc hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-auc:0.81944\n",
      "[40]\tvalidation_0-auc:0.82311\n",
      "[60]\tvalidation_0-auc:0.82555\n",
      "[80]\tvalidation_0-auc:0.82724\n",
      "[100]\tvalidation_0-auc:0.82868\n",
      "[120]\tvalidation_0-auc:0.82959\n",
      "[140]\tvalidation_0-auc:0.83041\n",
      "[160]\tvalidation_0-auc:0.83107\n",
      "[180]\tvalidation_0-auc:0.83182\n",
      "[200]\tvalidation_0-auc:0.83255\n",
      "[220]\tvalidation_0-auc:0.83302\n",
      "[240]\tvalidation_0-auc:0.83356\n",
      "[260]\tvalidation_0-auc:0.83414\n",
      "[280]\tvalidation_0-auc:0.83459\n",
      "[300]\tvalidation_0-auc:0.83497\n",
      "[320]\tvalidation_0-auc:0.83515\n",
      "[340]\tvalidation_0-auc:0.83539\n",
      "[360]\tvalidation_0-auc:0.83566\n",
      "[380]\tvalidation_0-auc:0.83600\n",
      "[400]\tvalidation_0-auc:0.83628\n",
      "[420]\tvalidation_0-auc:0.83653\n",
      "[440]\tvalidation_0-auc:0.83676\n",
      "[460]\tvalidation_0-auc:0.83695\n",
      "[480]\tvalidation_0-auc:0.83712\n",
      "[500]\tvalidation_0-auc:0.83729\n",
      "[520]\tvalidation_0-auc:0.83767\n",
      "[540]\tvalidation_0-auc:0.83785\n",
      "[560]\tvalidation_0-auc:0.83801\n",
      "[580]\tvalidation_0-auc:0.83823\n",
      "[600]\tvalidation_0-auc:0.83831\n",
      "[620]\tvalidation_0-auc:0.83835\n",
      "[640]\tvalidation_0-auc:0.83838\n",
      "[660]\tvalidation_0-auc:0.83846\n",
      "[680]\tvalidation_0-auc:0.83852\n",
      "[700]\tvalidation_0-auc:0.83853\n",
      "[720]\tvalidation_0-auc:0.83853\n",
      "[740]\tvalidation_0-auc:0.83859\n",
      "[760]\tvalidation_0-auc:0.83868\n",
      "[780]\tvalidation_0-auc:0.83864\n",
      "[800]\tvalidation_0-auc:0.83870\n",
      "[820]\tvalidation_0-auc:0.83870\n",
      "[840]\tvalidation_0-auc:0.83866\n",
      "[860]\tvalidation_0-auc:0.83865\n",
      "[880]\tvalidation_0-auc:0.83863\n",
      "[900]\tvalidation_0-auc:0.83875\n",
      "[920]\tvalidation_0-auc:0.83876\n",
      "[940]\tvalidation_0-auc:0.83880\n",
      "[960]\tvalidation_0-auc:0.83889\n",
      "[980]\tvalidation_0-auc:0.83883\n",
      "[1000]\tvalidation_0-auc:0.83880\n",
      "[1020]\tvalidation_0-auc:0.83875\n",
      "[1040]\tvalidation_0-auc:0.83873\n",
      "[1060]\tvalidation_0-auc:0.83876\n",
      "Stopping. Best iteration:\n",
      "[961]\tvalidation_0-auc:0.83891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBClassifier(n_estimators=5000, max_depth=8, booster='gbtree', base_score=0.5,\n",
    "                      learning_rate=0.01, reg_lambda=20, subsample=0.8, colsample_bytree=0.8,\n",
    "                      eval_metric='auc', verbose=2020, random_state=9090)\n",
    "\n",
    "model1.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val1 = model1.predict_proba(validation)[:,1]\n",
    "pred1 = model1.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:33] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.78521\n",
      "Will train until validation_0-auc hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-auc:0.81891\n",
      "[40]\tvalidation_0-auc:0.82254\n",
      "[60]\tvalidation_0-auc:0.82461\n",
      "[80]\tvalidation_0-auc:0.82579\n",
      "[100]\tvalidation_0-auc:0.82713\n",
      "[120]\tvalidation_0-auc:0.82795\n",
      "[140]\tvalidation_0-auc:0.82883\n",
      "[160]\tvalidation_0-auc:0.82908\n",
      "[180]\tvalidation_0-auc:0.83006\n",
      "[200]\tvalidation_0-auc:0.83072\n",
      "[220]\tvalidation_0-auc:0.83144\n",
      "[240]\tvalidation_0-auc:0.83200\n",
      "[260]\tvalidation_0-auc:0.83239\n",
      "[280]\tvalidation_0-auc:0.83277\n",
      "[300]\tvalidation_0-auc:0.83300\n",
      "[320]\tvalidation_0-auc:0.83344\n",
      "[340]\tvalidation_0-auc:0.83351\n",
      "[360]\tvalidation_0-auc:0.83380\n",
      "[380]\tvalidation_0-auc:0.83404\n",
      "[400]\tvalidation_0-auc:0.83411\n",
      "[420]\tvalidation_0-auc:0.83435\n",
      "[440]\tvalidation_0-auc:0.83459\n",
      "[460]\tvalidation_0-auc:0.83504\n",
      "[480]\tvalidation_0-auc:0.83539\n",
      "[500]\tvalidation_0-auc:0.83559\n",
      "[520]\tvalidation_0-auc:0.83587\n",
      "[540]\tvalidation_0-auc:0.83613\n",
      "[560]\tvalidation_0-auc:0.83630\n",
      "[580]\tvalidation_0-auc:0.83646\n",
      "[600]\tvalidation_0-auc:0.83674\n",
      "[620]\tvalidation_0-auc:0.83684\n",
      "[640]\tvalidation_0-auc:0.83697\n",
      "[660]\tvalidation_0-auc:0.83700\n",
      "[680]\tvalidation_0-auc:0.83717\n",
      "[700]\tvalidation_0-auc:0.83726\n",
      "[720]\tvalidation_0-auc:0.83729\n",
      "[740]\tvalidation_0-auc:0.83740\n",
      "[760]\tvalidation_0-auc:0.83740\n",
      "[780]\tvalidation_0-auc:0.83742\n",
      "[800]\tvalidation_0-auc:0.83748\n",
      "[820]\tvalidation_0-auc:0.83757\n",
      "[840]\tvalidation_0-auc:0.83772\n",
      "[860]\tvalidation_0-auc:0.83781\n",
      "[880]\tvalidation_0-auc:0.83784\n",
      "[900]\tvalidation_0-auc:0.83790\n",
      "[920]\tvalidation_0-auc:0.83790\n",
      "[940]\tvalidation_0-auc:0.83794\n",
      "[960]\tvalidation_0-auc:0.83792\n",
      "[980]\tvalidation_0-auc:0.83796\n",
      "[1000]\tvalidation_0-auc:0.83788\n",
      "[1020]\tvalidation_0-auc:0.83791\n",
      "[1040]\tvalidation_0-auc:0.83786\n",
      "[1060]\tvalidation_0-auc:0.83783\n",
      "Stopping. Best iteration:\n",
      "[974]\tvalidation_0-auc:0.83799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = XGBClassifier(n_estimators=5000, max_depth=7, booster='gbtree', base_score=0.7,\n",
    "                      learning_rate=0.01, reg_lambda=10, subsample=0.9, colsample_bytree=0.9,\n",
    "                      eval_metric='auc', verbose=2020, random_state=2020)\n",
    "\n",
    "model2.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val2 = model2.predict_proba(validation)[:,1]\n",
    "pred2 = model2.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:55] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.76804\n",
      "Will train until validation_0-auc hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-auc:0.80767\n",
      "[40]\tvalidation_0-auc:0.81031\n",
      "[60]\tvalidation_0-auc:0.81350\n",
      "[80]\tvalidation_0-auc:0.81615\n",
      "[100]\tvalidation_0-auc:0.81841\n",
      "[120]\tvalidation_0-auc:0.81958\n",
      "[140]\tvalidation_0-auc:0.82077\n",
      "[160]\tvalidation_0-auc:0.82229\n",
      "[180]\tvalidation_0-auc:0.82347\n",
      "[200]\tvalidation_0-auc:0.82457\n",
      "[220]\tvalidation_0-auc:0.82563\n",
      "[240]\tvalidation_0-auc:0.82662\n",
      "[260]\tvalidation_0-auc:0.82720\n",
      "[280]\tvalidation_0-auc:0.82793\n",
      "[300]\tvalidation_0-auc:0.82863\n",
      "[320]\tvalidation_0-auc:0.82914\n",
      "[340]\tvalidation_0-auc:0.82968\n",
      "[360]\tvalidation_0-auc:0.83036\n",
      "[380]\tvalidation_0-auc:0.83071\n",
      "[400]\tvalidation_0-auc:0.83118\n",
      "[420]\tvalidation_0-auc:0.83149\n",
      "[440]\tvalidation_0-auc:0.83183\n",
      "[460]\tvalidation_0-auc:0.83208\n",
      "[480]\tvalidation_0-auc:0.83235\n",
      "[500]\tvalidation_0-auc:0.83260\n",
      "[520]\tvalidation_0-auc:0.83282\n",
      "[540]\tvalidation_0-auc:0.83315\n",
      "[560]\tvalidation_0-auc:0.83336\n",
      "[580]\tvalidation_0-auc:0.83361\n",
      "[600]\tvalidation_0-auc:0.83390\n",
      "[620]\tvalidation_0-auc:0.83412\n",
      "[640]\tvalidation_0-auc:0.83433\n",
      "[660]\tvalidation_0-auc:0.83458\n",
      "[680]\tvalidation_0-auc:0.83482\n",
      "[700]\tvalidation_0-auc:0.83496\n",
      "[720]\tvalidation_0-auc:0.83522\n",
      "[740]\tvalidation_0-auc:0.83540\n",
      "[760]\tvalidation_0-auc:0.83556\n",
      "[780]\tvalidation_0-auc:0.83560\n",
      "[800]\tvalidation_0-auc:0.83568\n",
      "[820]\tvalidation_0-auc:0.83582\n",
      "[840]\tvalidation_0-auc:0.83595\n",
      "[860]\tvalidation_0-auc:0.83603\n",
      "[880]\tvalidation_0-auc:0.83609\n",
      "[900]\tvalidation_0-auc:0.83623\n",
      "[920]\tvalidation_0-auc:0.83631\n",
      "[940]\tvalidation_0-auc:0.83639\n",
      "[960]\tvalidation_0-auc:0.83649\n",
      "[980]\tvalidation_0-auc:0.83664\n",
      "[1000]\tvalidation_0-auc:0.83676\n",
      "[1020]\tvalidation_0-auc:0.83687\n",
      "[1040]\tvalidation_0-auc:0.83692\n",
      "[1060]\tvalidation_0-auc:0.83707\n",
      "[1080]\tvalidation_0-auc:0.83716\n",
      "[1100]\tvalidation_0-auc:0.83726\n",
      "[1120]\tvalidation_0-auc:0.83730\n",
      "[1140]\tvalidation_0-auc:0.83740\n",
      "[1160]\tvalidation_0-auc:0.83745\n",
      "[1180]\tvalidation_0-auc:0.83751\n",
      "[1200]\tvalidation_0-auc:0.83751\n",
      "[1220]\tvalidation_0-auc:0.83757\n",
      "[1240]\tvalidation_0-auc:0.83761\n",
      "[1260]\tvalidation_0-auc:0.83771\n",
      "[1280]\tvalidation_0-auc:0.83776\n",
      "[1300]\tvalidation_0-auc:0.83779\n",
      "[1320]\tvalidation_0-auc:0.83784\n",
      "[1340]\tvalidation_0-auc:0.83786\n",
      "[1360]\tvalidation_0-auc:0.83795\n",
      "[1380]\tvalidation_0-auc:0.83800\n",
      "[1400]\tvalidation_0-auc:0.83799\n",
      "[1420]\tvalidation_0-auc:0.83800\n",
      "[1440]\tvalidation_0-auc:0.83802\n",
      "[1460]\tvalidation_0-auc:0.83806\n",
      "[1480]\tvalidation_0-auc:0.83808\n",
      "[1500]\tvalidation_0-auc:0.83813\n",
      "[1520]\tvalidation_0-auc:0.83818\n",
      "[1540]\tvalidation_0-auc:0.83823\n",
      "[1560]\tvalidation_0-auc:0.83815\n",
      "[1580]\tvalidation_0-auc:0.83816\n",
      "[1600]\tvalidation_0-auc:0.83826\n",
      "[1620]\tvalidation_0-auc:0.83822\n",
      "[1640]\tvalidation_0-auc:0.83829\n",
      "[1660]\tvalidation_0-auc:0.83830\n",
      "[1680]\tvalidation_0-auc:0.83828\n",
      "[1700]\tvalidation_0-auc:0.83832\n",
      "[1720]\tvalidation_0-auc:0.83833\n",
      "[1740]\tvalidation_0-auc:0.83835\n",
      "[1760]\tvalidation_0-auc:0.83834\n",
      "[1780]\tvalidation_0-auc:0.83832\n",
      "[1800]\tvalidation_0-auc:0.83838\n",
      "[1820]\tvalidation_0-auc:0.83841\n",
      "[1840]\tvalidation_0-auc:0.83835\n",
      "[1860]\tvalidation_0-auc:0.83826\n",
      "[1880]\tvalidation_0-auc:0.83832\n",
      "[1900]\tvalidation_0-auc:0.83830\n",
      "Stopping. Best iteration:\n",
      "[1815]\tvalidation_0-auc:0.83844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = XGBClassifier(n_estimators=5000, max_depth=5, booster='gbtree', base_score=0.5,\n",
    "                      learning_rate=0.01, reg_lambda=70, subsample=0.7, colsample_bytree=0.7,\n",
    "                      eval_metric='auc', verbose=2020, random_state=3030)\n",
    "\n",
    "model3.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val3 = model3.predict_proba(validation)[:,1]\n",
    "pred3 = model3.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:30:05] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.68933\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-logloss:0.62630\n",
      "[40]\tvalidation_0-logloss:0.58049\n",
      "[60]\tvalidation_0-logloss:0.54687\n",
      "[80]\tvalidation_0-logloss:0.52076\n",
      "[100]\tvalidation_0-logloss:0.50081\n",
      "[120]\tvalidation_0-logloss:0.48527\n",
      "[140]\tvalidation_0-logloss:0.47315\n",
      "[160]\tvalidation_0-logloss:0.46322\n",
      "[180]\tvalidation_0-logloss:0.45538\n",
      "[200]\tvalidation_0-logloss:0.44905\n",
      "[220]\tvalidation_0-logloss:0.44385\n",
      "[240]\tvalidation_0-logloss:0.43956\n",
      "[260]\tvalidation_0-logloss:0.43603\n",
      "[280]\tvalidation_0-logloss:0.43304\n",
      "[300]\tvalidation_0-logloss:0.43049\n",
      "[320]\tvalidation_0-logloss:0.42823\n",
      "[340]\tvalidation_0-logloss:0.42647\n",
      "[360]\tvalidation_0-logloss:0.42480\n",
      "[380]\tvalidation_0-logloss:0.42341\n",
      "[400]\tvalidation_0-logloss:0.42229\n",
      "[420]\tvalidation_0-logloss:0.42130\n",
      "[440]\tvalidation_0-logloss:0.42043\n",
      "[460]\tvalidation_0-logloss:0.41964\n",
      "[480]\tvalidation_0-logloss:0.41889\n",
      "[500]\tvalidation_0-logloss:0.41830\n",
      "[520]\tvalidation_0-logloss:0.41782\n",
      "[540]\tvalidation_0-logloss:0.41735\n",
      "[560]\tvalidation_0-logloss:0.41691\n",
      "[580]\tvalidation_0-logloss:0.41645\n",
      "[600]\tvalidation_0-logloss:0.41606\n",
      "[620]\tvalidation_0-logloss:0.41573\n",
      "[640]\tvalidation_0-logloss:0.41543\n",
      "[660]\tvalidation_0-logloss:0.41506\n",
      "[680]\tvalidation_0-logloss:0.41478\n",
      "[700]\tvalidation_0-logloss:0.41450\n",
      "[720]\tvalidation_0-logloss:0.41416\n",
      "[740]\tvalidation_0-logloss:0.41389\n",
      "[760]\tvalidation_0-logloss:0.41364\n",
      "[780]\tvalidation_0-logloss:0.41331\n",
      "[800]\tvalidation_0-logloss:0.41305\n",
      "[820]\tvalidation_0-logloss:0.41280\n",
      "[840]\tvalidation_0-logloss:0.41260\n",
      "[860]\tvalidation_0-logloss:0.41246\n",
      "[880]\tvalidation_0-logloss:0.41229\n",
      "[900]\tvalidation_0-logloss:0.41210\n",
      "[920]\tvalidation_0-logloss:0.41187\n",
      "[940]\tvalidation_0-logloss:0.41165\n",
      "[960]\tvalidation_0-logloss:0.41146\n",
      "[980]\tvalidation_0-logloss:0.41136\n",
      "[1000]\tvalidation_0-logloss:0.41120\n",
      "[1020]\tvalidation_0-logloss:0.41106\n",
      "[1040]\tvalidation_0-logloss:0.41089\n",
      "[1060]\tvalidation_0-logloss:0.41082\n",
      "[1080]\tvalidation_0-logloss:0.41062\n",
      "[1100]\tvalidation_0-logloss:0.41045\n",
      "[1120]\tvalidation_0-logloss:0.41032\n",
      "[1140]\tvalidation_0-logloss:0.41017\n",
      "[1160]\tvalidation_0-logloss:0.41007\n",
      "[1180]\tvalidation_0-logloss:0.40997\n",
      "[1200]\tvalidation_0-logloss:0.40990\n",
      "[1220]\tvalidation_0-logloss:0.40983\n",
      "[1240]\tvalidation_0-logloss:0.40978\n",
      "[1260]\tvalidation_0-logloss:0.40970\n",
      "[1280]\tvalidation_0-logloss:0.40964\n",
      "[1300]\tvalidation_0-logloss:0.40954\n",
      "[1320]\tvalidation_0-logloss:0.40946\n",
      "[1340]\tvalidation_0-logloss:0.40940\n",
      "[1360]\tvalidation_0-logloss:0.40935\n",
      "[1380]\tvalidation_0-logloss:0.40934\n",
      "[1400]\tvalidation_0-logloss:0.40931\n",
      "[1420]\tvalidation_0-logloss:0.40930\n",
      "[1440]\tvalidation_0-logloss:0.40924\n",
      "[1460]\tvalidation_0-logloss:0.40915\n",
      "[1480]\tvalidation_0-logloss:0.40912\n",
      "[1500]\tvalidation_0-logloss:0.40911\n",
      "[1520]\tvalidation_0-logloss:0.40901\n",
      "[1540]\tvalidation_0-logloss:0.40897\n",
      "[1560]\tvalidation_0-logloss:0.40892\n",
      "[1580]\tvalidation_0-logloss:0.40886\n",
      "[1600]\tvalidation_0-logloss:0.40888\n",
      "[1620]\tvalidation_0-logloss:0.40881\n",
      "[1640]\tvalidation_0-logloss:0.40879\n",
      "[1660]\tvalidation_0-logloss:0.40875\n",
      "[1680]\tvalidation_0-logloss:0.40868\n",
      "[1700]\tvalidation_0-logloss:0.40867\n",
      "[1720]\tvalidation_0-logloss:0.40869\n",
      "[1740]\tvalidation_0-logloss:0.40867\n",
      "[1760]\tvalidation_0-logloss:0.40869\n",
      "[1780]\tvalidation_0-logloss:0.40870\n",
      "[1800]\tvalidation_0-logloss:0.40865\n",
      "[1820]\tvalidation_0-logloss:0.40864\n",
      "[1840]\tvalidation_0-logloss:0.40862\n",
      "[1860]\tvalidation_0-logloss:0.40858\n",
      "[1880]\tvalidation_0-logloss:0.40853\n",
      "[1900]\tvalidation_0-logloss:0.40849\n",
      "[1920]\tvalidation_0-logloss:0.40846\n",
      "[1940]\tvalidation_0-logloss:0.40845\n",
      "[1960]\tvalidation_0-logloss:0.40843\n",
      "[1980]\tvalidation_0-logloss:0.40846\n",
      "[2000]\tvalidation_0-logloss:0.40851\n",
      "[2020]\tvalidation_0-logloss:0.40848\n",
      "[2040]\tvalidation_0-logloss:0.40845\n",
      "[2060]\tvalidation_0-logloss:0.40843\n",
      "[2080]\tvalidation_0-logloss:0.40848\n",
      "[2100]\tvalidation_0-logloss:0.40846\n",
      "[2120]\tvalidation_0-logloss:0.40840\n",
      "[2140]\tvalidation_0-logloss:0.40842\n",
      "[2160]\tvalidation_0-logloss:0.40839\n",
      "[2180]\tvalidation_0-logloss:0.40843\n",
      "[2200]\tvalidation_0-logloss:0.40846\n",
      "[2220]\tvalidation_0-logloss:0.40843\n",
      "[2240]\tvalidation_0-logloss:0.40844\n",
      "Stopping. Best iteration:\n",
      "[2157]\tvalidation_0-logloss:0.40839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4 = XGBClassifier(n_estimators=5000, max_depth=4, booster='dart', base_score=0.5,\n",
    "                      learning_rate=0.01, reg_lambda=100, subsample=0.8, colsample_bytree=0.8,\n",
    "                      eval_metric='logloss', verbose=2020, random_state=4040)\n",
    "\n",
    "model4.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val4 = model4.predict_proba(validation)[:,1]\n",
    "pred4 = model4.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:59] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.98550\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-logloss:0.81734\n",
      "[40]\tvalidation_0-logloss:0.71046\n",
      "[60]\tvalidation_0-logloss:0.63733\n",
      "[80]\tvalidation_0-logloss:0.58528\n",
      "[100]\tvalidation_0-logloss:0.54688\n",
      "[120]\tvalidation_0-logloss:0.51839\n",
      "[140]\tvalidation_0-logloss:0.49654\n",
      "[160]\tvalidation_0-logloss:0.47987\n",
      "[180]\tvalidation_0-logloss:0.46704\n",
      "[200]\tvalidation_0-logloss:0.45718\n",
      "[220]\tvalidation_0-logloss:0.44938\n",
      "[240]\tvalidation_0-logloss:0.44331\n",
      "[260]\tvalidation_0-logloss:0.43838\n",
      "[280]\tvalidation_0-logloss:0.43443\n",
      "[300]\tvalidation_0-logloss:0.43121\n",
      "[320]\tvalidation_0-logloss:0.42845\n",
      "[340]\tvalidation_0-logloss:0.42621\n",
      "[360]\tvalidation_0-logloss:0.42438\n",
      "[380]\tvalidation_0-logloss:0.42282\n",
      "[400]\tvalidation_0-logloss:0.42151\n",
      "[420]\tvalidation_0-logloss:0.42043\n",
      "[440]\tvalidation_0-logloss:0.41942\n",
      "[460]\tvalidation_0-logloss:0.41853\n",
      "[480]\tvalidation_0-logloss:0.41785\n",
      "[500]\tvalidation_0-logloss:0.41725\n",
      "[520]\tvalidation_0-logloss:0.41679\n",
      "[540]\tvalidation_0-logloss:0.41627\n",
      "[560]\tvalidation_0-logloss:0.41582\n",
      "[580]\tvalidation_0-logloss:0.41529\n",
      "[600]\tvalidation_0-logloss:0.41486\n",
      "[620]\tvalidation_0-logloss:0.41452\n",
      "[640]\tvalidation_0-logloss:0.41431\n",
      "[660]\tvalidation_0-logloss:0.41409\n",
      "[680]\tvalidation_0-logloss:0.41386\n",
      "[700]\tvalidation_0-logloss:0.41362\n",
      "[720]\tvalidation_0-logloss:0.41344\n",
      "[740]\tvalidation_0-logloss:0.41330\n",
      "[760]\tvalidation_0-logloss:0.41312\n",
      "[780]\tvalidation_0-logloss:0.41299\n",
      "[800]\tvalidation_0-logloss:0.41281\n",
      "[820]\tvalidation_0-logloss:0.41267\n",
      "[840]\tvalidation_0-logloss:0.41250\n",
      "[860]\tvalidation_0-logloss:0.41239\n",
      "[880]\tvalidation_0-logloss:0.41234\n",
      "[900]\tvalidation_0-logloss:0.41221\n",
      "[920]\tvalidation_0-logloss:0.41210\n",
      "[940]\tvalidation_0-logloss:0.41206\n",
      "[960]\tvalidation_0-logloss:0.41197\n",
      "[980]\tvalidation_0-logloss:0.41192\n",
      "[1000]\tvalidation_0-logloss:0.41184\n",
      "[1020]\tvalidation_0-logloss:0.41178\n",
      "[1040]\tvalidation_0-logloss:0.41168\n",
      "[1060]\tvalidation_0-logloss:0.41162\n",
      "[1080]\tvalidation_0-logloss:0.41159\n",
      "[1100]\tvalidation_0-logloss:0.41154\n",
      "[1120]\tvalidation_0-logloss:0.41149\n",
      "[1140]\tvalidation_0-logloss:0.41139\n",
      "[1160]\tvalidation_0-logloss:0.41129\n",
      "[1180]\tvalidation_0-logloss:0.41124\n",
      "[1200]\tvalidation_0-logloss:0.41120\n",
      "[1220]\tvalidation_0-logloss:0.41114\n",
      "[1240]\tvalidation_0-logloss:0.41109\n",
      "[1260]\tvalidation_0-logloss:0.41105\n",
      "[1280]\tvalidation_0-logloss:0.41103\n",
      "[1300]\tvalidation_0-logloss:0.41098\n",
      "[1320]\tvalidation_0-logloss:0.41093\n",
      "[1340]\tvalidation_0-logloss:0.41091\n",
      "[1360]\tvalidation_0-logloss:0.41091\n",
      "[1380]\tvalidation_0-logloss:0.41093\n",
      "[1400]\tvalidation_0-logloss:0.41085\n",
      "[1420]\tvalidation_0-logloss:0.41082\n",
      "[1440]\tvalidation_0-logloss:0.41081\n",
      "[1460]\tvalidation_0-logloss:0.41075\n",
      "[1480]\tvalidation_0-logloss:0.41076\n",
      "[1500]\tvalidation_0-logloss:0.41073\n",
      "[1520]\tvalidation_0-logloss:0.41071\n",
      "[1540]\tvalidation_0-logloss:0.41069\n",
      "[1560]\tvalidation_0-logloss:0.41070\n",
      "[1580]\tvalidation_0-logloss:0.41072\n",
      "[1600]\tvalidation_0-logloss:0.41068\n",
      "[1620]\tvalidation_0-logloss:0.41068\n",
      "Stopping. Best iteration:\n",
      "[1530]\tvalidation_0-logloss:0.41067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model5 = XGBClassifier(n_estimators=5000, max_depth=5, booster='gbtree', base_score=0.7,\n",
    "                      learning_rate=0.01, reg_lambda=80, subsample=1, colsample_bytree=0.9,\n",
    "                      eval_metric='logloss', verbose=2020, random_state=5050)\n",
    "\n",
    "model5.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val5 = model5.predict_proba(validation)[:,1]\n",
    "pred5 = model5.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:33:04] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.96219\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[20]\tvalidation_0-logloss:0.61984\n",
      "[40]\tvalidation_0-logloss:0.50746\n",
      "[60]\tvalidation_0-logloss:0.46023\n",
      "[80]\tvalidation_0-logloss:0.43812\n",
      "[100]\tvalidation_0-logloss:0.42666\n",
      "[120]\tvalidation_0-logloss:0.42023\n",
      "[140]\tvalidation_0-logloss:0.41656\n",
      "[160]\tvalidation_0-logloss:0.41433\n",
      "[180]\tvalidation_0-logloss:0.41289\n",
      "[200]\tvalidation_0-logloss:0.41183\n",
      "[220]\tvalidation_0-logloss:0.41092\n",
      "[240]\tvalidation_0-logloss:0.41061\n",
      "[260]\tvalidation_0-logloss:0.41001\n",
      "[280]\tvalidation_0-logloss:0.40956\n",
      "[300]\tvalidation_0-logloss:0.40937\n",
      "[320]\tvalidation_0-logloss:0.40920\n",
      "[340]\tvalidation_0-logloss:0.40880\n",
      "[360]\tvalidation_0-logloss:0.40858\n",
      "[380]\tvalidation_0-logloss:0.40868\n",
      "[400]\tvalidation_0-logloss:0.40883\n",
      "[420]\tvalidation_0-logloss:0.40879\n",
      "[440]\tvalidation_0-logloss:0.40888\n",
      "Stopping. Best iteration:\n",
      "[350]\tvalidation_0-logloss:0.40844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model6 = XGBClassifier(n_estimators=5000, max_depth=9, booster='gbtree', base_score=0.7,\n",
    "                      learning_rate=0.033, reg_lambda=150, subsample=0.7, colsample_bytree=1,\n",
    "                      eval_metric='logloss', verbose=2020, random_state=5050)\n",
    "\n",
    "model6.fit(traindata, target, early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=20)\n",
    "val6 = model6.predict_proba(validation)[:,1]\n",
    "pred6 = model6.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_open = np.column_stack((pred1, pred2, pred3, pred4))\n",
    "#stack_p = np.column_stack((val1, val2, val3, val4, val5, val6, val7, val8))\n",
    "stack = np.column_stack((val1, val2, val3, val4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_open1 = np.column_stack((pred1, pred2, pred3, pred4, pred5, pred6))\n",
    "#stack_p = np.column_stack((val1, val2, val3, val4, val5, val6, val7, val8))\n",
    "stack1 = np.column_stack((val1, val2, val3, val4, val5, val6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()\n",
    "#meta_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced', verbose=2)\n",
    "meta_model.fit(stack1, valid_target)\n",
    "#final_val_pred = meta_model.predict(stack_p)\n",
    "final_open_pred1 = meta_model.predict(stack_open1)\n",
    " \n",
    "#print(show_evaluation(final_val_pred, valid2_lithology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32442302, 0.35150856, 0.37237084, ..., 0.28555363, 0.49234748,\n",
       "       0.21292952], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_open_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31822655, 0.34873137, 0.37208906, ..., 0.27496397, 0.49478737,\n",
       "       0.21215343], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_open_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(prediction, filename):\n",
    "    sample = pd.read_csv('SampleSubmission.csv')\n",
    "    test = pd.read_csv('Test.csv')\n",
    "    sample.Applicant_ID = test.Applicant_ID\n",
    "    sample.default_status = prediction\n",
    "    sample.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(final_open_pred, '4-stack-xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(final_open_pred1, '6-stack-xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_avg = (final_open_pred+final_open_pred1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(final_open_pred1, '6-4-stack-xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
